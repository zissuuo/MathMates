{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv('item_pool.csv')\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer\n",
    "X = vectorizer.fit_transform(df['question'])\n",
    "Y = vectorizer.transform([question])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "cosine_sim = cosine_similarity(Y, X)\n",
    "cosine_sim = cosine_sim.flatten()\n",
    "\n",
    "# 코사인 유사도를 데이터프레임에 추가\n",
    "df['cosine_sim'] = cosine_sim\n",
    "\n",
    "# 성능 평가\n",
    "tfidf_df = df.sort_values(by='cosine_sim', ascending=False).head(5)\n",
    "tfidf = len(tfidf_df[tfidf_df['chapter']==chapter])\n",
    "tfidf_score = tfidf/5\n",
    "tfidf_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word2Vec** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('item_pool.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "sentences = [question.split() for question in questions]\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_vector(sentence, model):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# 데이터프레임의 질문들을 벡터로 변환\n",
    "df['vector'] = df['question'].apply(lambda x: get_sentence_vector(x, model))\n",
    "\n",
    "# input question을 벡터로 변환\n",
    "question_vector = get_sentence_vector(question, model).reshape(1, -1)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "df['cosine_sim'] = df['vector'].apply(lambda x: cosine_similarity([x], question_vector).flatten()[0])\n",
    "\n",
    "# 유사도 기준으로 데이터프레임 정렬\n",
    "word2vec_df = df.sort_values(by='cosine_sim', ascending=False)\n",
    "\n",
    "word2vec_df.drop(columns=['vector'], inplace=True)\n",
    "\n",
    "word2vec_df = word2vec_df.head(5)\n",
    "word2vec = len(word2vec_df[word2vec_df['chapter']==chapter])\n",
    "word2vec_score = word2vec/5\n",
    "word2vec_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Doc2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('item_pool.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "# TaggedDocument로 변환\n",
    "tagged_data = [TaggedDocument(words=question.split(), tags=[i]) for i, question in enumerate(questions)]\n",
    "\n",
    "# Doc2Vec 모델 훈련\n",
    "model = Doc2Vec(tagged_data, vector_size=100, window=5, min_count=1, workers=4, epochs=40)\n",
    "\n",
    "def get_doc2vec_vector(sentence, model):\n",
    "    words = sentence.split()\n",
    "    return model.infer_vector(words)\n",
    "\n",
    "# 데이터프레임의 질문들을 벡터로 변환\n",
    "df['vector'] = df['question'].apply(lambda x: get_doc2vec_vector(x, model))\n",
    "\n",
    "# input question을 벡터로 변환\n",
    "question_vector = get_doc2vec_vector(question, model).reshape(1, -1)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "df['cosine_sim'] = df['vector'].apply(lambda x: cosine_similarity([x], question_vector).flatten()[0])\n",
    "\n",
    "# 유사도 기준으로 데이터프레임 정렬\n",
    "doc2vec_df = df.sort_values(by='cosine_sim', ascending=False)\n",
    "\n",
    "doc2vec_df.drop(columns=['vector'], inplace=True)\n",
    "\n",
    "doc2vec_df = doc2vec_df.head(5)\n",
    "doc2vec = len(doc2vec_df[doc2vec_df['chapter']==chapter])\n",
    "doc2vec_score = doc2vec/5\n",
    "doc2vec_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KoBERT** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# KoBERT 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('kykim/bert-kor-base')\n",
    "model = BertModel.from_pretrained('kykim/bert-kor-base')\n",
    "\n",
    "def get_bert_vector(sentence, tokenizer, model):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy().flatten()\n",
    "\n",
    "df = pd.read_csv('item_pool.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "# 데이터프레임의 질문들을 벡터로 변환\n",
    "df['vector'] = df['question'].apply(lambda x: get_bert_vector(x, tokenizer, model))\n",
    "\n",
    "# input question을 벡터로 변환\n",
    "question_vector = get_bert_vector(question, tokenizer, model).reshape(1, -1)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "df['cosine_sim'] = df['vector'].apply(lambda x: cosine_similarity([x], question_vector).flatten()[0])\n",
    "\n",
    "# 유사도 기준으로 데이터프레임 정렬\n",
    "bert_df = df.sort_values(by='cosine_sim', ascending=False)\n",
    "\n",
    "bert_df.drop(columns=['vector'], inplace=True)\n",
    "\n",
    "bert_df = bert_df.head(5)\n",
    "bert_df\n",
    "bert = len(bert_df[bert_df['chapter']==chapter])\n",
    "bert_score = bert/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4,\n",
       " 0.8,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.append(tfidf_score)\n",
    "score.append(word2vec_score)\n",
    "score.append(doc2vec_score)\n",
    "score.append(bert_score)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>Word2Vec</th>\n",
       "      <th>Doc2Vec</th>\n",
       "      <th>BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Try1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Try2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Try3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Try4</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Try5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TF-IDF  Word2Vec  Doc2Vec  BERT\n",
       "Try1       0.40      0.80     0.20  0.40\n",
       "Try2       0.80      0.40     0.20  0.80\n",
       "Try3       0.60      0.80     0.20  0.60\n",
       "Try4       0.80      0.60     0.00  0.40\n",
       "Try5       0.00      0.20     0.00  0.00\n",
       "Average    0.52      0.56     0.12  0.44"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame([score[4*i:4*(i+1)] for i in range(5)],\n",
    "                  columns=['TF-IDF', 'Word2Vec', 'Doc2Vec', 'BERT'],\n",
    "                  index=['Try1', 'Try2', 'Try3', 'Try4', 'Try5'])\n",
    "\n",
    "column_means = score_df.mean()\n",
    "\n",
    "score_df.loc['Average'] = column_means\n",
    "\n",
    "score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
